"""
#TODO: docs
"""
from duckdb.experimental.spark.sql.functions import printf

#########################   These values should not need to be changed between runs, but may change depending on your
#         CONFIG        #   operating system, filepaths, and preferred output location.
#########################

ww_source_dir = r"W:\documents\2026_RT_Reports"         # Parent directory of the YYYYMMDD_RT_Report folders
snm_source_dir = r"J:\paperwork\0_UCSB_DWR_Project\2026_RT_Reports"
rt_report_pattern = "_RT_report"

ww_table_data = {
    "01" : "Pacific Northwest",
    "02" : "North Continental",
    "03" : "South Continental",
    "04" : "Intermountain",
}

snm_table_data = {
    "05" : "Sierra Nevada",
    "10" : "Elevation Banded",
}
#########################
#       END CONFIG      #
#########################

from utils import merge_swe_csv
import re
import glob
import os
from pathlib import Path
import pandas as pd
from jinja2 import Template, Environment, FileSystemLoader
import argparse

def get_output_dir(date:int, report_type:str) -> str:
    # TODO: docs
    source_dir = None
    match report_type:
        case 'WW':
            source_dir = ww_source_dir
        case 'SNM':
            source_dir = snm_source_dir
        case _:
            raise Exception(f"Unrecognized report type: {report_type}")
    output_dir=os.path.join(source_dir, str(date) + rt_report_pattern, "Report", f"{date}_{report_type}_TEXtables")
    return output_dir

def escape_latex(text):
    """
    Escape special LaTeX characters in text.
    """
    replacements = {
        '&': r'\&',
        '%': r'\%',
        '$': r'\$',
        '#': r'\#',
        '_': r'\_',
        '{': r'\{',
        '}': r'\}',
        '~': r'\textasciitilde{}',
        '^': r'\^{}',
        '\\': r'\textbackslash{}',
        'ยง': r'\S{}',  # Section symbol
    }
    for char, replacement in replacements.items():
        text = text.replace(char, replacement)
    return text

def interpret_ids(ids: str, report_type: str) -> list[str]:
    """
    Interprets the --tables regex flag

    :param ids: String value of the --tables flag as generated by parser.parse_args()
    :param report_type: Type of report to interpret figures for. Acceptable values: "WW", "SNM"
    :return: List of interpreted table IDs to generate tables for
    :rtype: list[str]
    """

    # Determine list of table ids based on report type
    all_ids = set()
    match report_type:
        case 'WW':
            all_ids = set(ww_table_data.keys())
        case 'SNM':
            all_ids = set(snm_table_data.keys())
        case _:
            raise Exception(f"Unrecognized report type: {report_type}")

    # Parse the argument passed into --tables
    patterns = ids.split(",")
    id_list = set()

    for pattern in patterns:
        pattern = pattern.lower()
        # Shortcut search when all or no IDs are specified
        if pattern in ["all","."]:
            return sorted(all_ids)
        elif pattern in ["none",""]:
            return []

        # Modify regular expression syntax to better support * wildcard
        regex_pattern = "^" + re.escape(pattern).replace("\\*", ".*") + "$"
        regex = re.compile(regex_pattern)

        # Match the pattern against all possible IDs
        pattern_found = False
        for id in all_ids-id_list:
            if regex.match(id):
                id_list.add(id)
                pattern_found = True
        if not pattern_found:
            # Pattern does not match any name in all_ids
            if pattern == "0":
                raise Exception(f"--tables pattern '0' not recognized! Did you mean 'none'?")
            else:
                raise Exception(f"--tables pattern '{pattern}' not recognized!")

    return sorted(id_list)


def generate_tables(report_type: str, date: int, ids: str, verbose: bool) -> None:
    # TODO: verbose
    """
    # TODO: docs
    """
    # Define output directory
    date_str = str(date)
    report_dir = None
    table_data = None
    match report_type:
        case "WW":
            report_dir = os.path.join(ww_source_dir, str(date) + rt_report_pattern)
            table_data = ww_table_data
        case "SNM":
            # report_dir = fr"J:\paperwork\0_UCSB_DWR_Project\{date_str[:4]}_RT_Reports\{date_str}_RT_report_ET"
            report_dir = os.path.join(snm_source_dir, str(date) + rt_report_pattern)
            table_data = snm_table_data
        case _:
            raise Exception(f"Unrecognized report type: {report_type}")

    use_this_dir = glob.glob(os.path.join(report_dir, "*UseThis*"))[0]
    table_dir = os.path.join(use_this_dir, "Tables")
    print(table_dir)
    output_tables_dir = get_output_dir(date, report_type)
    os.makedirs(output_tables_dir, exist_ok=True)

    # Determine which tables to generate
    id_list = interpret_ids(ids, report_type)

    # Merge WW tables 04a and 04b into a single table
    # if report_type == "WW" and "04" in id_list:
    #     table04a = os.path.join(table_dir, f"INMT1_{date}_Table04a_final.csv")
    #     table04b = os.path.join(table_dir, f"INMT2_{date}_Table04b_final.csv")
    #     table04_output = os.path.join(table_dir, f"INMT0_{date}_Table04_final.csv")
    #     if not os.path.exists(table04_output):
    #         merge_swe_csv(table04a, table04b, table04_output)

    # Generate tables
    for table_id in id_list:
        print(f"Generating table {table_id}...")

        matches = glob.glob(os.path.join(table_dir, f"*{table_id}_final.csv"))
        # TODO: error handling
        if len(matches) == 0:
            print(f"No table {table_id} found!")
        table = matches[0]
        print(table)

        # Read in the csv
        df = pd.read_csv(table,encoding='latin-1')

        # Check if this is an elevation band table by looking for "Elevation Band" in header
        is_elevation_table = "Elevation Band" in df.iloc[0].astype(str).values
        print(df.iloc[0].astype(str).values)
        print(f"Is elevation table: {is_elevation_table}")

        # df = df.iloc[:, 1:] # Drop the first column containing indices

        # Format SNODAS dates to 1 decimal place (matching our SWE precision)
        last_col = df.columns[-1]
        df.loc[1:, last_col] = (
            pd.to_numeric(df.loc[1:, last_col], errors="coerce")
            .round(1)
        )

        # Check how many dates have data (first report does not have a previous date)
        row0 = df.iloc[0].astype(str)
        date_count = row0.str.contains("Avg").sum()
        print(f"Date count: {date_count}")
        if date_count == 0:
            # TODO: error handling
            pass

        print(f"Row 4 {df.iloc[3]}")

        # Determine column offset based on table type
        col_offset = 2 if is_elevation_table else 1

        # Get current date and previous date if it exists
        if date_count > 1:
            previous_date = df.iloc[0, col_offset].strip("%").replace(" Avg.", "")
            current_date = df.iloc[0, col_offset+1].strip("%").replace(" Avg.", "")
        else:
            current_date = df.iloc[0, col_offset].strip("%").replace(" Avg.", "")

        # Get header data
        headers = {}
        if is_elevation_table:
            headers[""] = ["Elevation Band"]
        headers["% of Average"] = (
            [previous_date, current_date] if date_count > 1 else [current_date]
        )
        headers["SWE (in)"] = (
            [previous_date, current_date] if date_count > 1 else [current_date]
        )
        headers[" "] = ["SCA"]
        if report_type == "WW":
            headers["  "] = ["Vol. (AF)"]
        else: # SNM
            headers["  "] = ["Vol. (AF)$\ddagger$"]
        headers["    "] = ["Area (mi$^2$)"]
        headers["Pillows"] = (
            [previous_date, current_date] if date_count > 1 else [current_date]
        )
        if "Surveys" in df.iloc[0].astype(str).values:
            if verbose: print("Including surveys.")
            headers["Surveys"] = (
                [previous_date, current_date] if date_count > 1 else [current_date]
            )
        headers["SNODAS* (in)"] = [current_date]

        # Check for ASO
        aso_corrected = df.iloc[:, 0].astype(str).str.contains("ยง").any()
        print("ASO Corrected: ", aso_corrected)

        # Escape LaTeX special characters in basin names (first column)
        df.iloc[:, 0] = df.iloc[:, 0].astype(str).apply(escape_latex)

        # Load table template
        templates_dir = Path(__file__).parent.parent / "report_templates"
        env = Environment(loader=FileSystemLoader(str(templates_dir)))

        # Select template based on table type
        template_name = "TEMPLATE_Elev_SWE_Table.tex" if is_elevation_table else "TEMPLATE_SWE_Table.tex"
        template = env.get_template(template_name)

        latex_table = template.render(df=df,
                                      title=table_data[table_id],
                                      headers=headers,
                                      date=date_str,
                                      aso_corrected=aso_corrected,)

        # Write table to LaTeX file in the output directory
        output_table = Path(output_tables_dir) / f"{date}_{report_type}_Table{table_id}.tex"
        with open(output_table, "w") as f:
            f.write(latex_table)

def main():
    # Parse input arguments and flags, see top of file for argument usage examples
    parser = argparse.ArgumentParser()
    parser.add_argument("report_type", type=str, help="Acceptable report types: WW")
    parser.add_argument("date", type=int, help="Date to process (YYYYMMDD)")
    parser.add_argument("--tables", default="all", type=str, help="Regex pattern(s) for table IDs to generate")
    parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output messages")
    args = parser.parse_args()

    if args.report_type in ["WW","SNM"]:
        generate_tables(args.report_type, args.date, args.tables, args.verbose)
    else:
        raise Exception(f"Unrecognized report type: {args.report_type}")

if __name__ == "__main__":
    main()